{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UQS44VC58dbb"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import unicodedata\n",
        "import regex as re\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import regex as re\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding,LSTM,Dense,Softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcsEhBWz8jyb",
        "outputId": "495e15a3-778a-49d5-ef9e-1e220ea1d005"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Creating data"
      ],
      "metadata": {
        "id": "yiEbYov-irAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/data_500k.csv\")\n",
        "df = df.dropna()\n",
        "df.rename(columns = {'original':'correct',\"modified\":\"wrong\"}, inplace = True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sgp1vR-Le_bn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8f7bbbed-c353-40bd-ffae-408d2bde182a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       correct          wrong\n",
              "0  they do not  they due not \n",
              "1   they do to   they do too \n",
              "2    i hope so     i hope so \n",
              "3     she okay      she okay \n",
              "4     let's go      let's go "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78611393-401b-47ba-8f7e-ac64a32c6ee4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>correct</th>\n",
              "      <th>wrong</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>they do not</td>\n",
              "      <td>they due not</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they do to</td>\n",
              "      <td>they do too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i hope so</td>\n",
              "      <td>i hope so</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she okay</td>\n",
              "      <td>she okay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>let's go</td>\n",
              "      <td>let's go</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78611393-401b-47ba-8f7e-ac64a32c6ee4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78611393-401b-47ba-8f7e-ac64a32c6ee4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78611393-401b-47ba-8f7e-ac64a32c6ee4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Distribution of length of sentences"
      ],
      "metadata": {
        "id": "8D_DBqFDg_D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_lengths = df['correct'].str.split().apply(len)\n",
        "wrng_lengths = df['wrong'].str.split().apply(len)\n",
        "\n",
        "\n",
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(corr_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(corr_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(corr_lengths, i))"
      ],
      "metadata": {
        "id": "thtb7enN-TEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eeb5f77-a3c2-4e35-cff8-aefbd126f600"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 4.0\n",
            "20 5.0\n",
            "30 6.0\n",
            "40 8.0\n",
            "50 10.0\n",
            "60 12.0\n",
            "70 15.0\n",
            "80 19.0\n",
            "90 27.0\n",
            "100 552.0\n",
            "90 27.0\n",
            "91 29.0\n",
            "92 30.0\n",
            "93 32.0\n",
            "94 34.0\n",
            "95 37.0\n",
            "96 40.0\n",
            "97 45.0\n",
            "98 51.0\n",
            "99 65.0\n",
            "100 552.0\n",
            "99.1 67.0\n",
            "99.2 69.0\n",
            "99.3 73.0\n",
            "99.4 76.0\n",
            "99.5 80.0\n",
            "99.6 86.0\n",
            "99.7 93.0\n",
            "99.8 104.0\n",
            "99.9 124.0\n",
            "100 552.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-6pcMyuREOR"
      },
      "source": [
        "> <font color=\"blue\"><b>We observe the values, 99.2% of the data points are having length &lt; 70, so select the sentences that have words &lt; 70 </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 70"
      ],
      "metadata": {
        "id": "EIbem0biqBHs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preparing data for ENCODER DECODER"
      ],
      "metadata": {
        "id": "pXJw57kChMbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['wrng_lengths'] = df['wrong'].str.split().apply(len)\n",
        "df = df[df['wrng_lengths'] < 70]\n",
        "\n",
        "df['corr_lengths'] = df['correct'].str.split().apply(len)\n",
        "df = df[df['corr_lengths'] < 70]\n",
        "\n",
        "df['corr_inp'] = '<start> ' + df['correct'].astype(str)\n",
        "df['corr_out'] = df['correct'].astype(str) + ' <end>'\n",
        "\n",
        "df = df.drop(['correct','corr_lengths','wrng_lengths'], axis=1)\n",
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlYyvkPT-0_z",
        "outputId": "e8fbd6a8-59d6-450d-f070-cfbc335dfebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           wrong             corr_inp           corr_out\n",
              "0  they due not   <start> they do not  they do not <end>\n",
              "1   they do too    <start> they do to   they do to <end>\n",
              "2     i hope so     <start> i hope so    i hope so <end>\n",
              "3      she okay      <start> she okay     she okay <end>\n",
              "4      let's go      <start> let's go     let's go <end>"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-635f8069-aabe-42f8-938c-532e0a632e1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wrong</th>\n",
              "      <th>corr_inp</th>\n",
              "      <th>corr_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>they due not</td>\n",
              "      <td>&lt;start&gt; they do not</td>\n",
              "      <td>they do not &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they do too</td>\n",
              "      <td>&lt;start&gt; they do to</td>\n",
              "      <td>they do to &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i hope so</td>\n",
              "      <td>&lt;start&gt; i hope so</td>\n",
              "      <td>i hope so &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she okay</td>\n",
              "      <td>&lt;start&gt; she okay</td>\n",
              "      <td>she okay &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>let's go</td>\n",
              "      <td>&lt;start&gt; let's go</td>\n",
              "      <td>let's go &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-635f8069-aabe-42f8-938c-532e0a632e1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-635f8069-aabe-42f8-938c-532e0a632e1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-635f8069-aabe-42f8-938c-532e0a632e1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0rSHbQbAAYXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNkmddZ1REOW"
      },
      "source": [
        "##4. Getting train and test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG50P52vhMu8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(df, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mp9dzm1hwv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60978768-864d-44f5-bc90-48e669d0f699"
      },
      "source": [
        "print(train.shape, validation.shape)\n",
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "train.iloc[0]['corr_inp']= str(train.iloc[0]['corr_inp'])+' <end>'\n",
        "train.iloc[0]['corr_out']= str(train.iloc[0]['corr_out'])+' <end>'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(481389, 3) (120348, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su69ZPzTsxmn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "94a07577-d4dd-430f-a60d-75ec3826ac6a"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    wrong  \\\n",
              "481931                          a runner cathedral woman    \n",
              "121168                                  shut up dillhole    \n",
              "10096                              a fine night mrs peel    \n",
              "545169                      go out and plug cord back in    \n",
              "55770   ware are you you're driving me crazy waiting l...   \n",
              "\n",
              "                                                 corr_inp  \\\n",
              "481931           <start> a runner cathedral a woman <end>   \n",
              "121168                           <start> shut up dillhole   \n",
              "10096                      <start> a fine night mrs peel    \n",
              "545169           <start> go out and plug the cord back in   \n",
              "55770   <start> where are you  you're driving me crazy...   \n",
              "\n",
              "                                                 corr_out  \n",
              "481931             a runner cathedral a woman <end> <end>  \n",
              "121168                             shut up dillhole <end>  \n",
              "10096                        a fine night mrs peel  <end>  \n",
              "545169             go out and plug the cord back in <end>  \n",
              "55770   where are you  you're driving me crazy waiting...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c85531ea-d8ad-40fc-a3ed-0adb17faf4d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wrong</th>\n",
              "      <th>corr_inp</th>\n",
              "      <th>corr_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>481931</th>\n",
              "      <td>a runner cathedral woman</td>\n",
              "      <td>&lt;start&gt; a runner cathedral a woman &lt;end&gt;</td>\n",
              "      <td>a runner cathedral a woman &lt;end&gt; &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121168</th>\n",
              "      <td>shut up dillhole</td>\n",
              "      <td>&lt;start&gt; shut up dillhole</td>\n",
              "      <td>shut up dillhole &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10096</th>\n",
              "      <td>a fine night mrs peel</td>\n",
              "      <td>&lt;start&gt; a fine night mrs peel</td>\n",
              "      <td>a fine night mrs peel  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545169</th>\n",
              "      <td>go out and plug cord back in</td>\n",
              "      <td>&lt;start&gt; go out and plug the cord back in</td>\n",
              "      <td>go out and plug the cord back in &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55770</th>\n",
              "      <td>ware are you you're driving me crazy waiting l...</td>\n",
              "      <td>&lt;start&gt; where are you  you're driving me crazy...</td>\n",
              "      <td>where are you  you're driving me crazy waiting...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c85531ea-d8ad-40fc-a3ed-0adb17faf4d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c85531ea-d8ad-40fc-a3ed-0adb17faf4d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c85531ea-d8ad-40fc-a3ed-0adb17faf4d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGqQDR8FWV3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "eb6e07c4-a465-4422-afcf-7de5b1b6c629"
      },
      "source": [
        "validation.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    wrong  \\\n",
              "134137                         am i becoming repetitious    \n",
              "603004  they guard hour uyouu know borders knight and ...   \n",
              "174490                  you gotta kid how old's your kid    \n",
              "59950   this shit's peanuts compared to what we gonna ...   \n",
              "493649  and then to prove your truly mine i'll plunder...   \n",
              "\n",
              "                                                 corr_inp  \\\n",
              "134137                  <start> am i becoming repetitious   \n",
              "603004  <start> they guard our uyouu know  borders nig...   \n",
              "174490          <start> you gotta kid  how old's your kid   \n",
              "59950   <start> this shit's peanuts compared to what w...   \n",
              "493649  <start> and then  to prove your truly mine  i'...   \n",
              "\n",
              "                                                 corr_out  \n",
              "134137                    am i becoming repetitious <end>  \n",
              "603004  they guard our uyouu know  borders night and d...  \n",
              "174490            you gotta kid  how old's your kid <end>  \n",
              "59950   this shit's peanuts compared to what we're gon...  \n",
              "493649  and then  to prove your truly mine  i'll plund...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20fa1028-e22f-4e4a-90c9-464702bad258\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wrong</th>\n",
              "      <th>corr_inp</th>\n",
              "      <th>corr_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134137</th>\n",
              "      <td>am i becoming repetitious</td>\n",
              "      <td>&lt;start&gt; am i becoming repetitious</td>\n",
              "      <td>am i becoming repetitious &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603004</th>\n",
              "      <td>they guard hour uyouu know borders knight and ...</td>\n",
              "      <td>&lt;start&gt; they guard our uyouu know  borders nig...</td>\n",
              "      <td>they guard our uyouu know  borders night and d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174490</th>\n",
              "      <td>you gotta kid how old's your kid</td>\n",
              "      <td>&lt;start&gt; you gotta kid  how old's your kid</td>\n",
              "      <td>you gotta kid  how old's your kid &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59950</th>\n",
              "      <td>this shit's peanuts compared to what we gonna ...</td>\n",
              "      <td>&lt;start&gt; this shit's peanuts compared to what w...</td>\n",
              "      <td>this shit's peanuts compared to what we're gon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493649</th>\n",
              "      <td>and then to prove your truly mine i'll plunder...</td>\n",
              "      <td>&lt;start&gt; and then  to prove your truly mine  i'...</td>\n",
              "      <td>and then  to prove your truly mine  i'll plund...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20fa1028-e22f-4e4a-90c9-464702bad258')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20fa1028-e22f-4e4a-90c9-464702bad258 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20fa1028-e22f-4e4a-90c9-464702bad258');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpuPONunjYKj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "702962bc-7140-4ff7-c663-69eca9ddc1e7"
      },
      "source": [
        "wrng_lengths = train['wrong'].str.split().apply(len)\n",
        "corr_lenths = train['corr_inp'].str.split().apply(len)\n",
        "import seaborn as sns\n",
        "sns.kdeplot(wrng_lengths)\n",
        "plt.show()\n",
        "sns.kdeplot(corr_lenths)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "1. We see majority of the sentences contains 0-40 words.\n",
        "2. We have ignored sentences with length more than 70."
      ],
      "metadata": {
        "id": "mrkn83qihatV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/TRAIN AND VALIDATION/train.csv\",index=False)\n",
        "\n",
        "validation.to_csv(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/TRAIN AND VALIDATION/validation.csv\",index=False)"
      ],
      "metadata": {
        "id": "LaSFrt_Fn0Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Tokenization of data"
      ],
      "metadata": {
        "id": "ZWpUStkXEFoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_wrng = Tokenizer()\n",
        "tknizer_wrng.fit_on_texts(train['wrong'].values)\n",
        "\n",
        "\n",
        "tknizer_corr = Tokenizer(filters='\\t\\n')\n",
        "tknizer_corr.fit_on_texts(train['corr_inp'].values)"
      ],
      "metadata": {
        "id": "esp7F9ls3RPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_wrng=len(tknizer_wrng.word_index.keys())\n",
        "print(vocab_size_wrng)\n",
        "vocab_size_corr=len(tknizer_corr.word_index.keys())\n",
        "print(vocab_size_corr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-owqetx3h89",
        "outputId": "56e53f51-978b-41f3-9125-0843661fdf9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65901\n",
            "65713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_corr.word_index['<start>'], tknizer_corr.word_index['<end>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nsEMBMc3pZh",
        "outputId": "62065369-73e4-4924-b9f7-ea0f74d6e731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 57429)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving\n",
        "with open('/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/tokenizer_wrong.pickle', 'wb') as handle:\n",
        "    pickle.dump(tknizer_wrng, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# saving\n",
        "with open('/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/tokenizer_correct.pickle', 'wb') as handle:\n",
        "    pickle.dump(tknizer_corr, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "OOH5SfwQsmh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zSH_1ydQMgWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOAD"
      ],
      "metadata": {
        "id": "JnG5e0uZMhze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/TRAIN AND VALIDATION/train.csv\")\n",
        "\n",
        "validation = pd.read_csv(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/TRAIN AND VALIDATION/validation.csv\")"
      ],
      "metadata": {
        "id": "n1owKPUUojWt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/tokenizer_wrong.pickle', 'rb') as handle:\n",
        "    tknizer_wrng = pickle.load(handle)\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/tokenizer_correct.pickle', 'rb') as handle:\n",
        "    tknizer_corr = pickle.load(handle)"
      ],
      "metadata": {
        "id": "0JOBmoCWovve"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT2R3D6MREOp"
      },
      "source": [
        "## 6.Creating embeddings for english sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e1z8oTCGxsU",
        "outputId": "9b5c39c0-8d31-4602-9bd6-91d0cf72788d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 17:35:54--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6030:18::a27d:5012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
            "--2022-11-12 17:35:54--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucd890683824f09a63d3a1dbcd46.dl.dropboxusercontent.com/cd/0/inline/BwoD1NA-29Pv00dZn0ig6KmMCx96IuJmwCpdI4OtBUcPXPc4sCQ2sn6xOe8M-dBf0_EHVCO4KRhEOdITvk5BYntQHPxR29M9wYFESw5TFEF4UTWpj7oOc42TGZ6xyu5kOeXlwJ0Z7NdQjSViBolVxU45W6-Vu_ukLJ9llCD3eyo2pA/file# [following]\n",
            "--2022-11-12 17:35:55--  https://ucd890683824f09a63d3a1dbcd46.dl.dropboxusercontent.com/cd/0/inline/BwoD1NA-29Pv00dZn0ig6KmMCx96IuJmwCpdI4OtBUcPXPc4sCQ2sn6xOe8M-dBf0_EHVCO4KRhEOdITvk5BYntQHPxR29M9wYFESw5TFEF4UTWpj7oOc42TGZ6xyu5kOeXlwJ0Z7NdQjSViBolVxU45W6-Vu_ukLJ9llCD3eyo2pA/file\n",
            "Resolving ucd890683824f09a63d3a1dbcd46.dl.dropboxusercontent.com (ucd890683824f09a63d3a1dbcd46.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to ucd890683824f09a63d3a1dbcd46.dl.dropboxusercontent.com (ucd890683824f09a63d3a1dbcd46.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: glove.6B.100d.txt\n",
            "\n",
            "glove.6B.100d.txt   100%[===================>] 331.04M  16.9MB/s    in 22s     \n",
            "\n",
            "2022-11-12 17:36:17 (15.3 MB/s) - glove.6B.100d.txt saved [347116733/347116733]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_wrng = 65901\n",
        "vocab_size_corr = 65713"
      ],
      "metadata": {
        "id": "JKO-XMY3pRXt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olaKF9rb_zz1"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix_enc = np.zeros((vocab_size_wrng+1, 100))\n",
        "for word, i in tknizer_wrng.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_enc[i] = embedding_vector\n",
        "\n",
        "\n",
        "\n",
        "embedding_matrix_dec = np.zeros((vocab_size_corr+1, 100))\n",
        "for word, i in tknizer_corr.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_dec[i] = embedding_vector"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qsdLRMyiG0M_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "##7. <font color='blue'>**Implement ATTENTION MODEL**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "### 7.1 <font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Lx_5NA24KzRp"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length,**kwargs):\n",
        "\n",
        "        super().__init__()\n",
        "        self.vocab_size = inp_vocab_size\n",
        "        self.embedding_dim = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.enc_units= lstm_size\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = 0,0,0\n",
        "        #Initialize Embedding layer\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\", weights=[embedding_matrix_enc], trainable=False)\n",
        "        # Intialize Encoder LSTM layer\n",
        "        self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "    \n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        print(\"ENCODER ==> INPUT SQUENCES SHAPE :\",input_sequence.shape)\n",
        "        input_embedd                           = self.embedding(input_sequence)\n",
        "        print(\"ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE :\",input_embedd.shape)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "\n",
        "      \n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      self.lstm_state_h = np.zeros((batch_size,self.enc_units))\n",
        "      self.lstm_state_c = np.zeros((batch_size,self.enc_units))\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "      config = super(Encoder,self).get_config()\n",
        "      config.update({\n",
        "          'vocab_size': self.vocab_size,\n",
        "          'embedding_dim':self.embedding_dim,\n",
        "          'input_length':self.input_length,\n",
        "          'enc_units':self.enc_units,\n",
        "          'lstm_output':self.lstm_output,\n",
        "          'lstm_state_h':self.lstm_state_h,\n",
        "          'lstm_state_c':self.lstm_state_c,\n",
        "          'embedding':self.embedding,\n",
        "          'lstm':self.lstm,\n",
        "      })\n",
        "      return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "### 7.2 <font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "c33rhABtEO9O"
      },
      "outputs": [],
      "source": [
        "\n",
        "#defing calss attention funactions\n",
        "\n",
        "class Attention ( tf.keras.layers.Layer ) :\n",
        "\n",
        "    def __init__ ( self , scoring_function , att_units ) :\n",
        "\n",
        "        super().__init__( )\n",
        "        self.scoring_function  = scoring_function\n",
        "        self.att_units =  att_units\n",
        "        if self.scoring_function == 'dot' :\n",
        "            pass\n",
        "        elif scoring_function == 'general' :\n",
        "            # Intialize variables for geraneal fun needed\n",
        "            self.wa = Dense ( att_units )\n",
        "        elif scoring_function == 'concat' :\n",
        "            self.w1 = Dense ( att_units )\n",
        "            self.w2 = Dense ( att_units ) \n",
        "            self.v = Dense ( 1 )\n",
        "\n",
        "    #defining call function\n",
        "    def call ( self , decoder_hidden_state , encoder_output ):\n",
        "\n",
        "        if self.scoring_function == 'dot' :\n",
        "            state = tf.expand_dims ( decoder_hidden_state , -1 )\n",
        "            score = tf.matmul ( encoder_output , state )\n",
        "            weights  = tf.nn.softmax ( score , axis = 1 )\n",
        "            weighted_out =  encoder_output * weights\n",
        "            context_vec =  tf.reduce_sum ( weighted_out , axis = 1 )\n",
        "            #returing its weights\n",
        "            # print(context_vec)\n",
        "            # print(weights)\n",
        "            return context_vec , weights\n",
        "        \n",
        "        elif self.scoring_function == 'general' :\n",
        "            state = tf.expand_dims ( decoder_hidden_state , 2 )                                    \n",
        "            score = tf.matmul ( self.wa (encoder_output ) , state )                        \n",
        "            weights = tf.nn.softmax ( score , axis = 1 )  \n",
        "            weighted_out = encoder_output * weights\n",
        "            context_vec = tf.reduce_sum ( weighted_out , axis = 1 )\n",
        "            #return contextvec and weights           \n",
        "            return context_vec , weights\n",
        "\n",
        "        elif self.scoring_function  == 'concat' :         \n",
        "            state = tf.expand_dims ( decoder_hidden_state , 1 )           \n",
        "            score = self.v ( tf.nn.tanh ( self.w1 ( state ) + self.w2 ( encoder_output ) ) )\n",
        "            weights = tf.nn.softmax ( score , axis = 1 )\n",
        "            #weighted output\n",
        "            weighted_out = encoder_output * weights            \n",
        "            context_vec = tf.reduce_sum ( weighted_out , axis = 1 )            \n",
        "            #returing weights       \n",
        "            return context_vec , weights \n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "      config = super(Attention,self).get_config()\n",
        "      config.update({\n",
        "          'scoring_function': self.scoring_function,\n",
        "          'att_units':self.att_units,\n",
        "          'wa':self.wa,\n",
        "          'w1':self.w1,\n",
        "          'w2':self.w2,\n",
        "          'v':self.v\n",
        "      })\n",
        "      return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "### 7.3 <font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Kc8m7lmOL097"
      },
      "outputs": [],
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "      super().__init__()\n",
        "      self.vocab_size = tar_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "      #Initialize Embedding layer\n",
        "      self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\", weights=[embedding_matrix_dec], trainable=False)\n",
        "      #Intialize Decoder LSTM layer\n",
        "      self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, name=\"Encoder_LSTM\") \n",
        "      #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "      self.dense   = Dense(self.vocab_size)\n",
        "      # self.dense   = Dense(self.vocab_size, activation='softmax')\n",
        "      self.attention                                                         = Attention(self.score_fun,self.att_units)\n",
        "      self.out_temp = []\n",
        "      self.decoder_final_state_h,self.decoder_final_state_c = [],[]\n",
        "      self.context_vector,self.attention_weights = [],[]\n",
        "      self.concat = []\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "    '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n",
        "    target_embedd                                                                   = self.embedding(input_to_decoder)\n",
        "    self.context_vector,self.attention_weights                                      = self.attention(state_h,encoder_output)\n",
        "\n",
        "    self.concat = tf.concat([tf.expand_dims(self.context_vector,1),target_embedd],axis=-1)\n",
        "    initial_states                                                                  = [state_h,state_c]\n",
        "    decoder_output,self.decoder_final_state_h,self.decoder_final_state_c            = self.lstm(self.concat, initial_state=initial_states)\n",
        "    # print(\"LSTM OUTPUT-->\",decoder_output[:5])\n",
        "    # decoder_output = tf.reshape(decoder_output,[tf.shape(decoder_output).numpy()[0],tf.shape(decoder_output).numpy()[2]])\n",
        "    decoder_output = tf.reshape(decoder_output,(-1,decoder_output.shape[2]))\n",
        "    output                                                                          = self.dense(decoder_output)\n",
        "    # print(\"DENSE OUTPUT-->\",output[:5])\n",
        "    # print(decoder_output.shape)\n",
        "    # print(output.shape)\n",
        "\n",
        "\n",
        "    return output,self.decoder_final_state_h,self.decoder_final_state_c,self.attention_weights,self.context_vector\n",
        "    # return np.array(output),self.decoder_final_state_h,self.decoder_final_state_c,self.attention_weights,self.context_vector\n",
        "\n",
        "  \n",
        "  def get_config(self):\n",
        "      config = super(One_Step_Decoder,self).get_config()\n",
        "      config.update({\n",
        "          'vocab_size': self.vocab_size,\n",
        "          'embedding_dim':self.embedding_dim,\n",
        "          'input_length':self.input_length,\n",
        "          'dec_units':self.dec_units,\n",
        "          'score_fun':self.score_fun,\n",
        "          'att_units':self.att_units,\n",
        "          'embedding':self.embedding,\n",
        "          'lstm':self.lstm,\n",
        "          'dense':self.dense,\n",
        "          'attention':self.attention,\n",
        "          'out_temp':self.out_temp,\n",
        "          'decoder_final_state_h':self.decoder_final_state_h,\n",
        "          'decoder_final_state_c':self.decoder_final_state_c,\n",
        "          'context_vector':self.context_vector,\n",
        "          'attention_weights':self.attention_weights,\n",
        "          'concat':self.concat,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "### 7.4 <font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NV-x31rj6Hc4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super().__init__()\n",
        "      self.vocab_size = out_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "      #Initialize Embedding layer\n",
        "      self.onestep_decoder = One_Step_Decoder(self.vocab_size, self.embedding_dim, self.input_length, self.dec_units ,self.score_fun ,self.att_units)\n",
        "      self.all_outputs = tf.TensorArray(tf.float32,size=2,name=\"output_arrays\")\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "    \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        self.all_outputs = tf.TensorArray(tf.float32,size=tf.shape(input_to_decoder)[1],name=\"output_arrays\")\n",
        "      \n",
        "        #Iterate till the length of the decoder input\n",
        "        for timestep in range(tf.shape (input_to_decoder)[1]):\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            output,decoder_hidden_state,decoder_cell_state,_,_ = self.onestep_decoder(input_to_decoder[:,timestep:timestep+1],encoder_output,decoder_hidden_state,decoder_cell_state)\n",
        "            # Store the output in tensorarray\n",
        "            self.all_outputs = self.all_outputs.write(timestep,output)\n",
        "        # Return the tensor array.\n",
        "        # print(\"self.all_outputs shape-->\",self.all_outputs.size())\n",
        "        # print(\"self.all_outputs-->\",self.all_outputs)\n",
        "        self.all_outputs = tf.transpose(self.all_outputs.stack(),[1,0,2])\n",
        "        return self.all_outputs\n",
        "\n",
        "    \n",
        "    def get_config(self):\n",
        "      config = super(One_Step_Decoder,self).get_config()\n",
        "      config.update({\n",
        "          'vocab_size': self.vocab_size,\n",
        "          'embedding_dim':self.embedding_dim,\n",
        "          'input_length':self.input_length,\n",
        "          'dec_units':self.dec_units,\n",
        "          'score_fun':self.score_fun,\n",
        "          'att_units':self.att_units,\n",
        "          'onestep_decoder':self.onestep_decoder,\n",
        "          'all_outputs':self.all_outputs\n",
        "      })\n",
        "      return config\n",
        "        \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "### 7.5 <font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 70\n",
        "enc_units = 256\n",
        "embedding_dim = 100"
      ],
      "metadata": {
        "id": "1ZrNEZdsNqIt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FfqBIe20MT3D"
      },
      "outputs": [],
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,score_fun):\n",
        "    #Intialize objects from encoder decoder\n",
        "    super().__init__()\n",
        "    self.score_fun = score_fun\n",
        "    self.encoder = Encoder(inp_vocab_size=vocab_size_wrng + 1, embedding_size=embedding_dim, input_length=encoder_inputs_length, lstm_size=enc_units)#https://stackoverflow.com/questions/48479915/what-is-the-preferred-ratio-between-the-vocabulary-size-and-embedding-dimension\n",
        "    self.decoder = Decoder(out_vocab_size=vocab_size_corr + 1, embedding_dim=embedding_dim, input_length=decoder_inputs_length, dec_units=enc_units,score_fun=self.score_fun,att_units=enc_units)\n",
        "    self.decoder_output = []\n",
        "  \n",
        "  \n",
        "  def call(self,data):\n",
        "\n",
        "    input,output = data[0],data[1]\n",
        "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    print(\"=\"*20, \"ENCODER\", \"=\"*20)\n",
        "    batch_size = 16\n",
        "    enc_initial_state = self.encoder.initialize_states(batch_size)\n",
        "    encoder_output, encoder_h, encoder_c = self.encoder(input,enc_initial_state)\n",
        "    print(\"ENCODER ==> OUTPUT SHAPE\",encoder_output.shape)\n",
        "    print(\"ENCODER ==> HIDDEN STATE SHAPE\",encoder_h.shape)\n",
        "    # print(\"ENCODER ==> CELL STATE SHAPE\", encoder_c.shape)\n",
        "    # print(\"=\"*20, \"DECODER\", \"=\"*20)\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    dec_initial_state = [encoder_h,encoder_c]\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    self.decoder_output                             = self.decoder(output, encoder_output,encoder_h,encoder_c)\n",
        "    # return the decoder output\n",
        "    return self.decoder_output\n",
        "\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(One_Step_Decoder,self).get_config()\n",
        "    config.update({\n",
        "        'score_fun':self.score_fun,\n",
        "        'encoder':self.encoder,\n",
        "        'decoder':self.decoder,\n",
        "        'decoder_output':self.decoder_output\n",
        "    })\n",
        "    return config\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "### 7.6 <font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QY_3izrXMs8y"
      },
      "outputs": [],
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqmICWSdREOu"
      },
      "source": [
        "### 7.7 <font color='blue'>Creating data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mBXRd_sus3C"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['wrong'].values\n",
        "        self.decoder_inps = data['corr_inp'].values\n",
        "        self.decoder_outs = data['corr_out'].values\n",
        "        self.wrng_tokenizer = tknizer_wrng\n",
        "        self.corr_tokenizer = tknizer_corr\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.wrng_tokenizer.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.corr_tokenizer.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.corr_tokenizer.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kl3ePGhCtKvJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEUZFHrPREO0"
      },
      "source": [
        "### 7.8 <font color='blue'>Model training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "\n",
        "log_dir=\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/TENSORBOARDS/dummy/logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349a6d14-8206-4aa2-fbc1-20f3a50114f0",
        "id": "WFIatq7HtK1Q"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define callbacks for learning rate scheduling and best checkpoints saving\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS\"+'/dummy.h5', save_weights_only=True, save_best_only=True, \\\n",
        "                                       mode='min', monitor='val_loss',verbose = 1),\n",
        "    tf.keras.callbacks.EarlyStopping( monitor='val_loss', min_delta=0.01, patience=2, verbose=1,  mode='auto',  baseline=None,  restore_best_weights=True),\n",
        "    tensorboard_callback\n",
        "]"
      ],
      "metadata": {
        "id": "HuAowFL4tK1R"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9XLLuKvr5Kn",
        "outputId": "2274c896-9f99-46c8-9c1b-b4429fcd37fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120348, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDKh6iikRUyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f813349-529c-4f14-f589-c9e3c77f64d4"
      },
      "source": [
        "train_dataset = Dataset(train, tknizer_wrng, tknizer_corr, max_length)\n",
        "test_dataset  = Dataset(validation, tknizer_wrng, tknizer_corr, max_length)\n",
        "\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=256)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=256)\n",
        "\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)\n",
        "print(test_dataloader[0][0][0].shape, test_dataloader[0][0][1].shape, test_dataloader[0][1].shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 70) (256, 70) (256, 70)\n",
            "(256, 70) (256, 70) (256, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_model4 = encoder_decoder(encoder_inputs_length=max_length,decoder_inputs_length=max_length,output_vocab_size=vocab_size_corr,score_fun='dot')\n",
        "optimizer = tf.keras.optimizers.Adam(0.001,clipnorm=0.001)\n",
        "full_model4.compile(optimizer = optimizer,loss=loss_function)"
      ],
      "metadata": {
        "id": "1pXfzMzObzk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = full_model4.fit(train_dataloader, epochs=25, validation_data=test_dataloader,callbacks = callbacks)\n",
        "full_model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZq24k0HbzgT",
        "outputId": "e9fc2cc9-df1f-4d88-b9b9-8a982d51f3aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== ENCODER ====================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (256, 70)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (256, 70, 100)\n",
            "ENCODER ==> OUTPUT SHAPE (256, 70, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (256, 256)\n",
            "Epoch 1/25\n",
            "==================== ENCODER ====================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (None, None, 100)\n",
            "ENCODER ==> OUTPUT SHAPE (None, None, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (None, 256)\n",
            "==================== ENCODER ====================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (None, None, 100)\n",
            "ENCODER ==> OUTPUT SHAPE (None, None, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (None, 256)\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 1.1978==================== ENCODER ====================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (None, None, 100)\n",
            "ENCODER ==> OUTPUT SHAPE (None, None, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (None, 256)\n",
            "\n",
            "Epoch 1: val_loss improved from 1.26200 to 1.08224, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 1001s 529ms/step - loss: 1.1978 - val_loss: 1.0822\n",
            "Epoch 2/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.9610\n",
            "Epoch 2: val_loss improved from 1.08224 to 0.83333, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 987s 525ms/step - loss: 0.9610 - val_loss: 0.8333\n",
            "Epoch 3/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.6886\n",
            "Epoch 3: val_loss improved from 0.83333 to 0.47787, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 991s 527ms/step - loss: 0.6886 - val_loss: 0.4779\n",
            "Epoch 4/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.3331\n",
            "Epoch 4: val_loss improved from 0.47787 to 0.24717, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 990s 527ms/step - loss: 0.3331 - val_loss: 0.2472\n",
            "Epoch 5/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.1955\n",
            "Epoch 5: val_loss improved from 0.24717 to 0.17081, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 988s 525ms/step - loss: 0.1955 - val_loss: 0.1708\n",
            "Epoch 6/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.1385\n",
            "Epoch 6: val_loss improved from 0.17081 to 0.13457, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 987s 525ms/step - loss: 0.1385 - val_loss: 0.1346\n",
            "Epoch 7/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.1050\n",
            "Epoch 7: val_loss improved from 0.13457 to 0.11164, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 987s 525ms/step - loss: 0.1050 - val_loss: 0.1116\n",
            "Epoch 8/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.0838\n",
            "Epoch 8: val_loss improved from 0.11164 to 0.09443, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 991s 527ms/step - loss: 0.0838 - val_loss: 0.0944\n",
            "Epoch 9/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.0693\n",
            "Epoch 9: val_loss improved from 0.09443 to 0.08429, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 990s 527ms/step - loss: 0.0693 - val_loss: 0.0843\n",
            "Epoch 10/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.0595\n",
            "Epoch 10: val_loss improved from 0.08429 to 0.07605, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 989s 526ms/step - loss: 0.0595 - val_loss: 0.0760\n",
            "Epoch 11/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.0529\n",
            "Epoch 11: val_loss improved from 0.07605 to 0.07014, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 989s 526ms/step - loss: 0.0529 - val_loss: 0.0701\n",
            "Epoch 12/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.0483\n",
            "Epoch 12: val_loss improved from 0.07014 to 0.06606, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "1880/1880 [==============================] - 989s 526ms/step - loss: 0.0483 - val_loss: 0.0661\n",
            "Epoch 13/25\n",
            "1880/1880 [==============================] - ETA: 0s - loss: 0.0442\n",
            "Epoch 13: val_loss improved from 0.06606 to 0.06151, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_2.h5\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "1880/1880 [==============================] - 989s 526ms/step - loss: 0.0442 - val_loss: 0.0615\n",
            "Epoch 13: early stopping\n",
            "Model: \"encoder_decoder_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_2 (Encoder)         multiple                  6955768   \n",
            "                                                                 \n",
            " decoder_2 (Decoder)         multiple                  24087610  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,043,378\n",
            "Trainable params: 17,881,778\n",
            "Non-trainable params: 13,161,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_model4.save_weights(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_BLEU_81.h5\")"
      ],
      "metadata": {
        "id": "ClkZebBBz0DA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.9 <font color='blue'>Loading the weights"
      ],
      "metadata": {
        "id": "UPgHvb2l4wq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = encoder_decoder(encoder_inputs_length=max_length,decoder_inputs_length=max_length,output_vocab_size=vocab_size_corr,score_fun='dot')\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "dummy.compile(optimizer = optimizer,loss=loss_function)\n",
        "dummy.fit(train_dataloader, epochs=1, validation_data=test_dataloader,callbacks = callbacks)\n",
        "\n",
        "\n",
        "dummy.load_weights('/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_BLEU_81.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh8xDLPUoc3G",
        "outputId": "f74c21c7-1278-4bcb-9715-856863fb132d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== ENCODER ====================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (4, 70)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (4, 70, 100)\n",
            "ENCODER ==> OUTPUT SHAPE (4, 70, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (4, 256)\n",
            "==================== ENCODER ====================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (None, None, 100)\n",
            "ENCODER ==> OUTPUT SHAPE (None, None, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (None, 256)\n",
            "==================== ENCODER ====================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (None, None, 100)\n",
            "ENCODER ==> OUTPUT SHAPE (None, None, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (None, 256)\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8797==================== ENCODER ====================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (None, None, 100)\n",
            "ENCODER ==> OUTPUT SHAPE (None, None, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (None, 256)\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.54958, saving model to /content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/dummy.h5\n",
            "25/25 [==============================] - 27s 806ms/step - loss: 1.8797 - val_loss: 1.5496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgkX_cLid_jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. PREDICT"
      ],
      "metadata": {
        "id": "o5AmezRCsB2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  \n",
        "  temp_token = tknizer_wrng.texts_to_sequences ( [ input_sentence ] )\n",
        "  temp_token  = pad_sequences ( temp_token , maxlen = vocab_size_wrng , dtype = 'int32' , padding = 'post' )\n",
        "\n",
        "\n",
        "\n",
        "  print(\"=\" * 30, \"Inference\", \"=\" * 30)\n",
        "  initial_state =  [np.zeros((1,64)) ,np.zeros((1,64))]\n",
        "  enc_output, enc_state_h, enc_state_c = dummy.layers[0](np.expand_dims(temp_token[0], 0),initial_state)\n",
        "  states_values = [enc_state_h, enc_state_c]\n",
        "\n",
        "  dec_inp = np.array ( tknizer_corr.word_index ['<start>'] ).reshape( 1 , 1 )\n",
        "  attention_weights_list = []\n",
        "\n",
        "\n",
        "  predicted_eng = \"\"\n",
        "  for i in range(max_length):\n",
        "\n",
        "    predictions , enc_state_h , enc_state_c , attention_weights , context_vector = dummy.layers[ 1 ].onestep_decoder( dec_inp, enc_output , enc_state_h, enc_state_c )\n",
        "    \n",
        "    word_ind  = np.argmax ( predictions,-1 )\n",
        "    pred_str = list ( tknizer_corr.word_index.keys( ) ) [ int ( word_ind - 1 ) ]\n",
        "\n",
        "    attention_weights_list.append ( attention_weights [0,:,0 ] )\n",
        "\n",
        "    predicted_eng+= pred_str + \" \"\n",
        "\n",
        "    dec_inp = word_ind.reshape(1,1)\n",
        "\n",
        "    if(pred_str == \"<end>\"):\n",
        "      # print(predicted_eng)\n",
        "      return predicted_eng, np.array ( attention_weights_list )\n",
        "  return predicted_eng, np.array ( attention_weights_list )\n",
        "\n"
      ],
      "metadata": {
        "id": "VlcugX_pr_7X"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "def plot_attention ( attention , sentence , predicted_sentence ) :\n",
        "       \n",
        "    sentence  = sentence.split()\n",
        "    #final sentence declaration\n",
        "    sentence  = sentence \n",
        "    \n",
        "    predicted_sentence =  predicted_sentence.split() + [ '<end>' ]    \n",
        "    fig = plt.figure(figsize =( 10 , 10 ))\n",
        "    ax = fig.add_subplot (1 , 1 , 1)\n",
        "    attention = attention [:len ( predicted_sentence ), :len(sentence) ]\n",
        "    \n",
        "    #matrix plot with proper arguments\n",
        "    ax.matshow(attention, cmap = 'viridis', vmin = 0.0)\n",
        "\n",
        "    \n",
        "    #fontsize as 14\n",
        "    fontdict = {'fontsize': 14}\n",
        "    #seting up axis labels argument\n",
        "    ax.set_xticklabels( [''] + sentence , fontdict = fontdict , rotation = 90 )\n",
        "    ax.set_yticklabels( [''] + predicted_sentence , fontdict = fontdict)\n",
        "    ax.xaxis.set_major_locator ( matplotlib.ticker.MultipleLocator (1) )\n",
        "    ax.yaxis.set_major_locator ( matplotlib.ticker.MultipleLocator (1) )\n",
        "    \n",
        "    ax.set_xlabel ( 'Input text' )   \n",
        "    ax.set_ylabel ( 'Output text' )\n",
        "    \n",
        "    #titles\n",
        "    plt.suptitle ('Attention weights')\n",
        "\n"
      ],
      "metadata": {
        "id": "8Z0Ub-xy61Av"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation['wrong' ].values[ 321 ] , validation[ \"corr_out\" ].values[ 321 ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCATDD4Hr_56",
        "outputId": "dd7ba4c3-5153-4964-d9c3-c6da2f2c15c5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('i sea you around ', \"i'll see you around <end>\")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining start time and end time\n",
        "pred_sent,attention_weights   = predict ( validation['wrong'].values[ 321 ] )\n",
        "pred_sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Md-mUMHur_2L",
        "outputId": "e95b22de-21bb-4a08-b5c2-552a506b5675"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i see you around <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting attention\n",
        "plot_attention ( attention_weights , validation['wrong'].values[321] , pred_sent )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "g3ZPJl0U7fF-",
        "outputId": "d66f01e0-7ac8-4313-b597-1de064db7ed6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Calculating BLEU Score"
      ],
      "metadata": {
        "id": "RE5mC_X2jpOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_sentences = list(train['wrong'])\n",
        "test_data_sentences_output = list(train['corr_out'])"
      ],
      "metadata": {
        "id": "mVz6syBmr_ul"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "indexes = random.sample(range(0, 111499), 1000)\n",
        "sentences_test = []\n",
        "sentences_test_output = []\n",
        "sentences_test_pred = []\n",
        "for each in tqdm(indexes):\n",
        "\n",
        "  sentences_test.append(test_data_sentences[each])\n",
        "  sentences_test_output.append(test_data_sentences_output[each])\n",
        "  ans,_ = predict(test_data_sentences[each])\n",
        "  sentences_test_pred.append(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8gDWA0Dr_ri",
        "outputId": "3d7c7af1-06d7-4e9e-b586-fb8d867bf187"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/1000 [00:00<01:12, 13.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 4/1000 [00:00<02:09,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 8/1000 [00:01<02:05,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 9/1000 [00:01<02:04,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 12/1000 [00:01<01:55,  8.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|         | 14/1000 [00:01<02:18,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|         | 17/1000 [00:02<02:07,  7.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|         | 19/1000 [00:02<02:24,  6.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 21/1000 [00:02<01:58,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 23/1000 [00:02<01:36, 10.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 25/1000 [00:03<01:41,  9.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|         | 27/1000 [00:03<01:48,  8.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|         | 29/1000 [00:03<02:24,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|         | 30/1000 [00:03<02:14,  7.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|         | 33/1000 [00:04<02:09,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|         | 35/1000 [00:04<02:09,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|         | 37/1000 [00:04<02:04,  7.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|         | 39/1000 [00:04<01:45,  9.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|         | 43/1000 [00:05<01:30, 10.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|         | 45/1000 [00:05<01:42,  9.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|         | 47/1000 [00:05<01:47,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|         | 49/1000 [00:06<02:22,  6.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|         | 53/1000 [00:06<01:57,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|         | 55/1000 [00:06<02:03,  7.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|         | 58/1000 [00:07<01:42,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|         | 60/1000 [00:07<02:19,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|         | 62/1000 [00:07<02:02,  7.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|         | 63/1000 [00:08<02:25,  6.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|         | 66/1000 [00:08<02:08,  7.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|         | 67/1000 [00:08<02:21,  6.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|         | 69/1000 [00:08<02:02,  7.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|         | 72/1000 [00:09<02:11,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|         | 74/1000 [00:09<02:36,  5.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|         | 78/1000 [00:10<01:43,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|         | 80/1000 [00:10<02:28,  6.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|         | 83/1000 [00:10<02:01,  7.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|         | 85/1000 [00:11<01:55,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|         | 87/1000 [00:11<01:58,  7.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|         | 90/1000 [00:11<01:40,  9.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|         | 93/1000 [00:12<01:52,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|         | 94/1000 [00:12<02:14,  6.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|         | 97/1000 [00:13<02:26,  6.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 99/1000 [00:13<02:06,  7.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|         | 101/1000 [00:13<02:25,  6.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|         | 104/1000 [00:14<02:16,  6.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 105/1000 [00:14<02:41,  5.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|         | 107/1000 [00:14<02:18,  6.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|         | 110/1000 [00:14<02:05,  7.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|         | 112/1000 [00:15<01:41,  8.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|        | 114/1000 [00:15<01:51,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|        | 117/1000 [00:15<01:32,  9.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|        | 118/1000 [00:15<01:39,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|        | 121/1000 [00:16<02:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|        | 123/1000 [00:16<01:41,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|        | 124/1000 [00:16<01:43,  8.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|        | 128/1000 [00:17<01:45,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|        | 130/1000 [00:17<01:53,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|        | 132/1000 [00:17<01:36,  9.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|        | 134/1000 [00:17<01:52,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|        | 138/1000 [00:18<01:37,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|        | 140/1000 [00:18<01:35,  8.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|        | 142/1000 [00:18<02:00,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|        | 143/1000 [00:18<01:51,  7.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|        | 147/1000 [00:19<01:26,  9.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|        | 149/1000 [00:19<01:26,  9.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|        | 151/1000 [00:19<01:43,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|        | 153/1000 [00:20<01:35,  8.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|        | 154/1000 [00:20<01:42,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|        | 157/1000 [00:20<02:01,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|        | 158/1000 [00:20<02:12,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|        | 161/1000 [00:21<02:00,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|        | 165/1000 [00:21<01:21, 10.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|        | 167/1000 [00:21<01:28,  9.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|        | 169/1000 [00:22<01:30,  9.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|        | 171/1000 [00:22<01:38,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|        | 172/1000 [00:22<01:53,  7.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|        | 174/1000 [00:22<01:51,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|        | 176/1000 [00:23<02:04,  6.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|        | 178/1000 [00:23<02:27,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|        | 180/1000 [00:23<01:57,  6.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|        | 184/1000 [00:24<01:27,  9.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|        | 185/1000 [00:24<01:35,  8.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|        | 188/1000 [00:24<01:36,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|        | 191/1000 [00:25<01:37,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|        | 194/1000 [00:25<01:17, 10.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 196/1000 [00:25<01:36,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 198/1000 [00:25<01:35,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|        | 202/1000 [00:26<01:33,  8.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|        | 205/1000 [00:26<01:38,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|        | 207/1000 [00:27<01:44,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|        | 209/1000 [00:27<02:18,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|        | 211/1000 [00:27<02:13,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|       | 215/1000 [00:28<01:44,  7.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|       | 217/1000 [00:28<01:35,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|       | 219/1000 [00:28<01:30,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|       | 221/1000 [00:28<01:26,  8.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|       | 224/1000 [00:29<01:21,  9.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|       | 226/1000 [00:29<01:30,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|       | 229/1000 [00:29<01:23,  9.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|       | 231/1000 [00:30<01:21,  9.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|       | 233/1000 [00:30<01:34,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|       | 235/1000 [00:30<01:35,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|       | 237/1000 [00:30<01:20,  9.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|       | 241/1000 [00:31<01:28,  8.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|       | 244/1000 [00:31<01:16,  9.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|       | 246/1000 [00:31<01:14, 10.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|       | 248/1000 [00:32<01:29,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|       | 249/1000 [00:32<01:49,  6.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|       | 251/1000 [00:32<01:46,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|       | 253/1000 [00:32<01:56,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|       | 256/1000 [00:33<01:55,  6.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|       | 259/1000 [00:33<01:33,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|       | 262/1000 [00:34<01:30,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|       | 264/1000 [00:34<01:19,  9.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|       | 267/1000 [00:34<01:17,  9.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|       | 269/1000 [00:34<01:06, 11.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|       | 273/1000 [00:35<00:58, 12.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|       | 275/1000 [00:35<01:02, 11.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|       | 277/1000 [00:35<00:55, 12.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|       | 279/1000 [00:35<01:14,  9.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|       | 282/1000 [00:36<01:40,  7.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|       | 284/1000 [00:36<01:29,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|       | 285/1000 [00:36<01:36,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|       | 288/1000 [00:37<01:28,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|       | 292/1000 [00:37<01:22,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|       | 294/1000 [00:37<01:24,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|       | 297/1000 [00:38<01:26,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 299/1000 [00:38<01:13,  9.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|       | 303/1000 [00:38<01:12,  9.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 305/1000 [00:39<01:13,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|       | 307/1000 [00:39<01:35,  7.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|       | 309/1000 [00:39<01:51,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|       | 311/1000 [00:40<01:37,  7.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|      | 314/1000 [00:40<01:28,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|      | 316/1000 [00:40<01:37,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|      | 317/1000 [00:41<01:51,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|      | 319/1000 [00:41<01:49,  6.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|      | 322/1000 [00:41<01:43,  6.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|      | 325/1000 [00:42<01:17,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|      | 327/1000 [00:42<01:21,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|      | 330/1000 [00:42<01:07,  9.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|      | 332/1000 [00:42<01:20,  8.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|      | 333/1000 [00:43<01:35,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|      | 334/1000 [00:43<01:46,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|      | 337/1000 [00:43<01:34,  6.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|      | 339/1000 [00:43<01:10,  9.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|      | 344/1000 [00:44<00:59, 10.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|      | 346/1000 [00:44<01:10,  9.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|      | 350/1000 [00:44<01:04, 10.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|      | 352/1000 [00:45<01:04, 10.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|      | 355/1000 [00:45<01:14,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|      | 356/1000 [00:45<01:57,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|      | 360/1000 [00:46<01:24,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|      | 363/1000 [00:46<01:13,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|      | 366/1000 [00:46<01:04,  9.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|      | 368/1000 [00:47<01:05,  9.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|      | 370/1000 [00:47<01:16,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|      | 372/1000 [00:47<01:14,  8.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|      | 376/1000 [00:48<01:13,  8.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|      | 378/1000 [00:48<01:06,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|      | 380/1000 [00:48<01:01, 10.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|      | 384/1000 [00:48<01:07,  9.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|      | 386/1000 [00:49<01:12,  8.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|      | 389/1000 [00:49<01:04,  9.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|      | 391/1000 [00:50<01:42,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|      | 393/1000 [00:50<01:40,  6.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|      | 396/1000 [00:50<01:14,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 397/1000 [00:50<01:31,  6.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 399/1000 [00:51<01:32,  6.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|      | 403/1000 [00:51<01:19,  7.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 405/1000 [00:51<01:05,  9.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|      | 409/1000 [00:52<00:54, 10.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|     | 413/1000 [00:52<00:52, 11.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|     | 415/1000 [00:52<00:54, 10.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|     | 419/1000 [00:53<01:01,  9.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|     | 421/1000 [00:53<01:10,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|     | 424/1000 [00:53<00:57, 10.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|     | 426/1000 [00:53<00:52, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|     | 428/1000 [00:54<00:52, 10.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|     | 430/1000 [00:54<00:58,  9.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|     | 432/1000 [00:54<01:03,  9.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|     | 435/1000 [00:55<01:16,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|     | 436/1000 [00:55<01:15,  7.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|     | 439/1000 [00:55<01:05,  8.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|     | 440/1000 [00:55<01:07,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|     | 441/1000 [00:55<01:20,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|     | 444/1000 [00:56<01:27,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|     | 446/1000 [00:56<01:10,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|     | 448/1000 [00:56<01:00,  9.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|     | 451/1000 [00:57<01:01,  8.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|     | 453/1000 [00:57<01:23,  6.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|     | 455/1000 [00:57<01:07,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|     | 457/1000 [00:58<01:18,  6.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|     | 459/1000 [00:58<01:08,  7.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|     | 462/1000 [00:58<00:54,  9.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|     | 464/1000 [00:58<01:19,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|     | 467/1000 [00:59<01:28,  6.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|     | 468/1000 [00:59<01:34,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|     | 469/1000 [01:00<01:43,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|     | 471/1000 [01:00<01:37,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|     | 473/1000 [01:00<01:32,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|     | 476/1000 [01:01<01:11,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|     | 479/1000 [01:01<01:02,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|     | 480/1000 [01:01<01:26,  6.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|     | 483/1000 [01:02<01:12,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|     | 485/1000 [01:02<01:21,  6.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|     | 487/1000 [01:02<01:09,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|     | 489/1000 [01:02<01:09,  7.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|     | 491/1000 [01:03<01:00,  8.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|     | 494/1000 [01:03<00:58,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|     | 497/1000 [01:03<00:57,  8.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|     | 500/1000 [01:04<01:04,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|     | 502/1000 [01:04<01:11,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|     | 506/1000 [01:04<00:44, 11.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|     | 508/1000 [01:05<00:44, 11.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|     | 510/1000 [01:05<00:57,  8.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|    | 513/1000 [01:05<01:05,  7.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|    | 515/1000 [01:05<00:53,  9.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|    | 517/1000 [01:06<00:49,  9.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|    | 519/1000 [01:06<01:00,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|    | 522/1000 [01:06<00:52,  9.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|    | 524/1000 [01:06<00:45, 10.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|    | 528/1000 [01:07<00:43, 10.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|    | 531/1000 [01:07<00:56,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|    | 534/1000 [01:08<00:53,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|    | 536/1000 [01:08<00:49,  9.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|    | 539/1000 [01:08<00:53,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|    | 541/1000 [01:08<00:57,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|    | 543/1000 [01:09<00:54,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|    | 545/1000 [01:09<01:01,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|    | 548/1000 [01:09<00:54,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|    | 551/1000 [01:10<00:50,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|    | 554/1000 [01:10<00:46,  9.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|    | 556/1000 [01:10<01:01,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|    | 558/1000 [01:11<01:09,  6.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|    | 561/1000 [01:11<00:51,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|    | 564/1000 [01:11<00:44,  9.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|    | 566/1000 [01:12<00:46,  9.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|    | 570/1000 [01:12<00:38, 11.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|    | 572/1000 [01:12<00:38, 11.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|    | 574/1000 [01:12<00:34, 12.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|    | 576/1000 [01:12<00:40, 10.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|    | 580/1000 [01:13<00:45,  9.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|    | 582/1000 [01:13<00:43,  9.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|    | 584/1000 [01:13<00:38, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|    | 588/1000 [01:14<00:38, 10.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|    | 590/1000 [01:14<00:40, 10.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|    | 592/1000 [01:14<00:43,  9.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|    | 594/1000 [01:15<01:04,  6.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 595/1000 [01:15<01:08,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|    | 597/1000 [01:15<01:10,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 598/1000 [01:15<01:10,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|    | 600/1000 [01:16<01:27,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|    | 602/1000 [01:16<01:14,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 604/1000 [01:16<00:50,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|    | 608/1000 [01:17<00:43,  8.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|    | 610/1000 [01:17<00:42,  9.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|    | 612/1000 [01:17<00:40,  9.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|   | 614/1000 [01:18<00:44,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|   | 618/1000 [01:18<00:35, 10.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|   | 620/1000 [01:18<00:34, 11.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|   | 622/1000 [01:18<00:45,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|   | 624/1000 [01:19<00:39,  9.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|   | 627/1000 [01:19<00:42,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|   | 629/1000 [01:19<00:42,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|   | 630/1000 [01:19<00:44,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|   | 634/1000 [01:20<00:37,  9.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|   | 636/1000 [01:20<00:36,  9.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|   | 638/1000 [01:20<00:35, 10.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|   | 641/1000 [01:21<00:45,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|   | 644/1000 [01:21<00:37,  9.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|   | 647/1000 [01:21<00:36,  9.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|   | 648/1000 [01:21<00:41,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|   | 650/1000 [01:22<00:53,  6.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|   | 653/1000 [01:22<00:40,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|   | 655/1000 [01:22<00:37,  9.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|   | 657/1000 [01:22<00:33, 10.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|   | 659/1000 [01:23<00:36,  9.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|   | 660/1000 [01:23<00:47,  7.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|   | 663/1000 [01:23<00:42,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|   | 666/1000 [01:24<00:37,  8.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|   | 669/1000 [01:24<00:34,  9.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|   | 671/1000 [01:24<00:33,  9.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|   | 675/1000 [01:24<00:30, 10.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|   | 677/1000 [01:25<00:30, 10.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|   | 680/1000 [01:25<00:40,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|   | 681/1000 [01:25<00:48,  6.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|   | 685/1000 [01:26<00:35,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|   | 687/1000 [01:26<00:34,  9.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|   | 688/1000 [01:26<00:36,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|   | 690/1000 [01:26<00:35,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|   | 692/1000 [01:27<00:50,  6.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|   | 693/1000 [01:27<00:49,  6.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 695/1000 [01:27<00:45,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 697/1000 [01:27<00:35,  8.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 699/1000 [01:28<00:30,  9.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 701/1000 [01:28<00:48,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 703/1000 [01:28<00:44,  6.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|   | 705/1000 [01:29<00:46,  6.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|   | 706/1000 [01:29<00:47,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|   | 710/1000 [01:29<00:38,  7.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|   | 711/1000 [01:30<00:41,  7.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|  | 713/1000 [01:30<00:32,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|  | 715/1000 [01:30<00:29,  9.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|  | 718/1000 [01:30<00:35,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|  | 721/1000 [01:31<00:29,  9.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|  | 724/1000 [01:31<00:38,  7.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|  | 726/1000 [01:31<00:31,  8.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|  | 729/1000 [01:32<00:33,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|  | 731/1000 [01:32<00:31,  8.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|  | 734/1000 [01:32<00:27,  9.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|  | 735/1000 [01:32<00:28,  9.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|  | 737/1000 [01:33<00:30,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|  | 739/1000 [01:33<00:32,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|  | 740/1000 [01:33<00:49,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|  | 743/1000 [01:34<00:45,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|  | 745/1000 [01:34<00:52,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|  | 747/1000 [01:35<00:48,  5.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|  | 748/1000 [01:35<00:50,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|  | 752/1000 [01:35<00:34,  7.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|  | 753/1000 [01:36<00:42,  5.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|  | 755/1000 [01:36<00:37,  6.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|  | 757/1000 [01:36<00:34,  7.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|  | 760/1000 [01:37<00:38,  6.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|  | 762/1000 [01:37<00:32,  7.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|  | 763/1000 [01:37<00:36,  6.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|  | 765/1000 [01:37<00:36,  6.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|  | 766/1000 [01:38<00:41,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|  | 769/1000 [01:38<00:36,  6.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|  | 772/1000 [01:38<00:30,  7.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|  | 775/1000 [01:39<00:27,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|  | 776/1000 [01:39<00:33,  6.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|  | 778/1000 [01:39<00:32,  6.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|  | 781/1000 [01:40<00:28,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|  | 783/1000 [01:40<00:35,  6.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|  | 786/1000 [01:40<00:28,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|  | 788/1000 [01:41<00:23,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|  | 790/1000 [01:41<00:21,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|  | 792/1000 [01:41<00:26,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|  | 795/1000 [01:42<00:28,  7.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 796/1000 [01:42<00:27,  7.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 798/1000 [01:42<00:25,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 799/1000 [01:42<00:25,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|  | 802/1000 [01:42<00:24,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 804/1000 [01:43<00:21,  9.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 805/1000 [01:43<00:21,  9.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|  | 807/1000 [01:43<00:22,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|  | 810/1000 [01:43<00:23,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%| | 813/1000 [01:44<00:22,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%| | 814/1000 [01:44<00:24,  7.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%| | 816/1000 [01:44<00:29,  6.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 817/1000 [01:45<00:40,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 818/1000 [01:45<00:49,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 819/1000 [01:45<00:46,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 820/1000 [01:45<00:44,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%| | 823/1000 [01:46<00:32,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 825/1000 [01:46<00:26,  6.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%| | 828/1000 [01:46<00:21,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%| | 830/1000 [01:47<00:23,  7.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%| | 831/1000 [01:47<00:25,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%| | 832/1000 [01:47<00:28,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%| | 833/1000 [01:47<00:33,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%| | 837/1000 [01:48<00:21,  7.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%| | 839/1000 [01:48<00:20,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%| | 841/1000 [01:48<00:16,  9.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%| | 844/1000 [01:48<00:16,  9.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%| | 846/1000 [01:49<00:19,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%| | 848/1000 [01:49<00:17,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%| | 850/1000 [01:49<00:16,  9.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%| | 854/1000 [01:50<00:14, 10.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%| | 858/1000 [01:50<00:14,  9.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%| | 860/1000 [01:50<00:14,  9.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%| | 862/1000 [01:51<00:16,  8.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%| | 865/1000 [01:51<00:16,  8.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%| | 867/1000 [01:51<00:15,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%| | 869/1000 [01:51<00:14,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%| | 871/1000 [01:52<00:14,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%| | 874/1000 [01:52<00:17,  7.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%| | 877/1000 [01:52<00:13,  9.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%| | 880/1000 [01:53<00:17,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%| | 882/1000 [01:53<00:17,  6.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%| | 883/1000 [01:53<00:16,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%| | 885/1000 [01:54<00:18,  6.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%| | 888/1000 [01:54<00:18,  6.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%| | 890/1000 [01:54<00:14,  7.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%| | 893/1000 [01:55<00:12,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 895/1000 [01:55<00:12,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%| | 898/1000 [01:55<00:10, 10.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%| | 901/1000 [01:56<00:11,  8.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 903/1000 [01:56<00:11,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%| | 905/1000 [01:56<00:11,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%| | 908/1000 [01:57<00:13,  6.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%| | 911/1000 [01:57<00:14,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|| 914/1000 [01:58<00:14,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|| 918/1000 [01:58<00:11,  7.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|| 919/1000 [01:58<00:10,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|| 922/1000 [01:59<00:10,  7.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|| 925/1000 [01:59<00:08,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|| 927/1000 [02:00<00:11,  6.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|| 929/1000 [02:00<00:09,  7.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|| 931/1000 [02:00<00:07,  9.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|| 932/1000 [02:00<00:09,  7.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|| 934/1000 [02:01<00:09,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|| 936/1000 [02:01<00:10,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|| 938/1000 [02:01<00:08,  6.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|| 939/1000 [02:01<00:11,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|| 941/1000 [02:02<00:09,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|| 944/1000 [02:02<00:08,  6.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|| 946/1000 [02:02<00:07,  7.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|| 947/1000 [02:02<00:06,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|| 950/1000 [02:03<00:08,  5.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|| 953/1000 [02:04<00:09,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|| 955/1000 [02:04<00:07,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|| 957/1000 [02:04<00:06,  7.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|| 961/1000 [02:05<00:05,  7.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|| 963/1000 [02:05<00:04,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|| 964/1000 [02:05<00:04,  7.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|| 966/1000 [02:06<00:05,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|| 968/1000 [02:06<00:04,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|| 970/1000 [02:06<00:05,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|| 971/1000 [02:07<00:06,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|| 974/1000 [02:07<00:05,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|| 976/1000 [02:08<00:04,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|| 979/1000 [02:08<00:02,  7.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|| 981/1000 [02:08<00:02,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|| 983/1000 [02:08<00:02,  7.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|| 985/1000 [02:09<00:01,  9.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|| 987/1000 [02:09<00:01,  7.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|| 989/1000 [02:09<00:01,  7.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|| 992/1000 [02:10<00:01,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|| 994/1000 [02:10<00:00,  7.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 996/1000 [02:10<00:00,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 998/1000 [02:11<00:00,  6.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n",
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1000/1000 [02:11<00:00,  7.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 65901)\n",
            "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 65901, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences_test[999])\n",
        "print(sentences_test_output[999])\n",
        "print(sentences_test_pred[999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx5M_vDrK4pf",
        "outputId": "e2445b36-0d56-4745-8dd7-55b5d42154a1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "okay this is important \n",
            "okay this is important <end>\n",
            "okay this is important <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iHiLdROM23l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13c4046-7fb7-43f6-97c2-8ed5abf96d5a"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk.translate.bleu_score as bleu\n",
        "total_score = 0\n",
        "\n",
        "\n",
        "for i in tqdm(range(len(sentences_test_output))):\n",
        "  reference = [sentences_test_output[i].split(),] # the original\n",
        "  translation = sentences_test_pred[i].split()# trasilated using model\n",
        "  total_score += bleu.sentence_bleu(reference, translation)\n",
        "\n",
        "avg_score = total_score/1000\n",
        "print(\"\\navg_score\",avg_score)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1000/1000 [00:00<00:00, 7459.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "avg_score 0.8140663037747174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OBSERVATIONS:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   Using simple ENCODER DECODER MODEL, we got a best validation_loss of 0.18 and an average BLEU score for 1000 random sentences of about 71%.\n",
        "2.   Using simple encoder decoder model WITH ATTENTION MECHANISM, we got a best validation_loss of 0.18 and an average BLEU score for 1000 random sentences of about 81% and according to https://cloud.google.com/translate/automl/docs/evaluate it is a pretty good score.\n",
        "\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n"
      ],
      "metadata": {
        "id": "yrp5GsCs8eTs"
      }
    }
  ]
}