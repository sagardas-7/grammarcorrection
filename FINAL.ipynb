{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TMm3ADQDLOfK",
        "lXn278lhLYRM",
        "ic-FNEbfL2DN",
        "6FHrurjUMGAi",
        "fC1T1EOoMTqC",
        "WVRxB-FDMJWL"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8AdnMdCymHL",
        "outputId": "219cf950-778c-4720-f75d-1b049483163a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import unicodedata\n",
        "import regex as re\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import unicodedata\n",
        "import regex as re\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding,LSTM,Dense,Softmax"
      ],
      "metadata": {
        "id": "i2B09qa615V3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/TRAIN AND VALIDATION/train.csv\")\n",
        "\n",
        "validation = pd.read_csv(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/TRAIN AND VALIDATION/validation.csv\")"
      ],
      "metadata": {
        "id": "aH-Qs3aS3UAM"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/tokenizer_wrong.pickle', 'rb') as handle:\n",
        "    tknizer_wrng = pickle.load(handle)\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/tokenizer_correct.pickle', 'rb') as handle:\n",
        "    tknizer_corr = pickle.load(handle)"
      ],
      "metadata": {
        "id": "2TmPZy2P2VkU"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT2R3D6MREOp"
      },
      "source": [
        "## 1.Creating embeddings for english sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e1z8oTCGxsU",
        "outputId": "0369d13f-f6a9-4ea4-eff2-605895ced8e9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-05 10:31:29--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
            "--2023-01-05 10:31:29--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce0d296225a3f7a402140f783ea.dl.dropboxusercontent.com/cd/0/inline/Bz8huJHkPhIaJOSbwz2QYF9WSYLNfVNJZhFMJmDjBu19xU6uKivj2lhwmhcYyzh_QT_lQTbvcCPiY7mbVUKHEtsCYsskKZxdpSjgY5v9ziMiIxLVlE5vvs_q3Y4jukapc5MlsQwW3VsSLr53PC7604BhX7ssCs5OKO5DdzNjvjbDEg/file# [following]\n",
            "--2023-01-05 10:31:30--  https://uce0d296225a3f7a402140f783ea.dl.dropboxusercontent.com/cd/0/inline/Bz8huJHkPhIaJOSbwz2QYF9WSYLNfVNJZhFMJmDjBu19xU6uKivj2lhwmhcYyzh_QT_lQTbvcCPiY7mbVUKHEtsCYsskKZxdpSjgY5v9ziMiIxLVlE5vvs_q3Y4jukapc5MlsQwW3VsSLr53PC7604BhX7ssCs5OKO5DdzNjvjbDEg/file\n",
            "Resolving uce0d296225a3f7a402140f783ea.dl.dropboxusercontent.com (uce0d296225a3f7a402140f783ea.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6025:15::a27d:450f\n",
            "Connecting to uce0d296225a3f7a402140f783ea.dl.dropboxusercontent.com (uce0d296225a3f7a402140f783ea.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘glove.6B.100d.txt.1’\n",
            "\n",
            "glove.6B.100d.txt.1 100%[===================>] 331.04M  12.8MB/s    in 24s     \n",
            "\n",
            "2023-01-05 10:31:55 (13.8 MB/s) - ‘glove.6B.100d.txt.1’ saved [347116733/347116733]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_wrng = 65901\n",
        "vocab_size_corr = 65713"
      ],
      "metadata": {
        "id": "JKO-XMY3pRXt"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olaKF9rb_zz1"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix_enc = np.zeros((vocab_size_wrng+1, 100))\n",
        "for word, i in tknizer_wrng.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_enc[i] = embedding_vector\n",
        "\n",
        "\n",
        "\n",
        "embedding_matrix_dec = np.zeros((vocab_size_corr+1, 100))\n",
        "for word, i in tknizer_corr.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_dec[i] = embedding_vector"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "##2. <font color='blue'>**Implement ATTENTION MODEL**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "### 2.1 <font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Lx_5NA24KzRp"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length,**kwargs):\n",
        "\n",
        "        super().__init__()\n",
        "        self.vocab_size = inp_vocab_size\n",
        "        self.embedding_dim = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.enc_units= lstm_size\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = 0,0,0\n",
        "        #Initialize Embedding layer\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\", weights=[embedding_matrix_enc], trainable=False)\n",
        "        # Intialize Encoder LSTM layer\n",
        "        self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "    \n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        # print(\"ENCODER ==> INPUT SQUENCES SHAPE :\",input_sequence.shape)\n",
        "        input_embedd                           = self.embedding(input_sequence)\n",
        "        # print(\"ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE :\",input_embedd.shape)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "\n",
        "      \n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      self.lstm_state_h = np.zeros((batch_size,self.enc_units))\n",
        "      self.lstm_state_c = np.zeros((batch_size,self.enc_units))\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "      config = super(Encoder,self).get_config()\n",
        "      config.update({\n",
        "          'vocab_size': self.vocab_size,\n",
        "          'embedding_dim':self.embedding_dim,\n",
        "          'input_length':self.input_length,\n",
        "          'enc_units':self.enc_units,\n",
        "          'lstm_output':self.lstm_output,\n",
        "          'lstm_state_h':self.lstm_state_h,\n",
        "          'lstm_state_c':self.lstm_state_c,\n",
        "          'embedding':self.embedding,\n",
        "          'lstm':self.lstm,\n",
        "      })\n",
        "      return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "### 2.2 <font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "c33rhABtEO9O"
      },
      "outputs": [],
      "source": [
        "\n",
        "#defing calss attention funactions\n",
        "\n",
        "class Attention ( tf.keras.layers.Layer ) :\n",
        "\n",
        "    def __init__ ( self , scoring_function , att_units ) :\n",
        "\n",
        "        super().__init__( )\n",
        "        self.scoring_function  = scoring_function\n",
        "        self.att_units =  att_units\n",
        "        if self.scoring_function == 'dot' :\n",
        "            pass\n",
        "        elif scoring_function == 'general' :\n",
        "            # Intialize variables for geraneal fun needed\n",
        "            self.wa = Dense ( att_units )\n",
        "        elif scoring_function == 'concat' :\n",
        "            self.w1 = Dense ( att_units )\n",
        "            self.w2 = Dense ( att_units ) \n",
        "            self.v = Dense ( 1 )\n",
        "\n",
        "    #defining call function\n",
        "    def call ( self , decoder_hidden_state , encoder_output ):\n",
        "\n",
        "        if self.scoring_function == 'dot' :\n",
        "            state = tf.expand_dims ( decoder_hidden_state , -1 )\n",
        "            score = tf.matmul ( encoder_output , state )\n",
        "            weights  = tf.nn.softmax ( score , axis = 1 )\n",
        "            weighted_out =  encoder_output * weights\n",
        "            context_vec =  tf.reduce_sum ( weighted_out , axis = 1 )\n",
        "            #returing its weights\n",
        "            # print(context_vec)\n",
        "            # print(weights)\n",
        "            return context_vec , weights\n",
        "        \n",
        "        elif self.scoring_function == 'general' :\n",
        "            state = tf.expand_dims ( decoder_hidden_state , 2 )                                    \n",
        "            score = tf.matmul ( self.wa (encoder_output ) , state )                        \n",
        "            weights = tf.nn.softmax ( score , axis = 1 )  \n",
        "            weighted_out = encoder_output * weights\n",
        "            context_vec = tf.reduce_sum ( weighted_out , axis = 1 )\n",
        "            #return contextvec and weights           \n",
        "            return context_vec , weights\n",
        "\n",
        "        elif self.scoring_function  == 'concat' :         \n",
        "            state = tf.expand_dims ( decoder_hidden_state , 1 )           \n",
        "            score = self.v ( tf.nn.tanh ( self.w1 ( state ) + self.w2 ( encoder_output ) ) )\n",
        "            weights = tf.nn.softmax ( score , axis = 1 )\n",
        "            #weighted output\n",
        "            weighted_out = encoder_output * weights            \n",
        "            context_vec = tf.reduce_sum ( weighted_out , axis = 1 )            \n",
        "            #returing weights       \n",
        "            return context_vec , weights \n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "      config = super(Attention,self).get_config()\n",
        "      config.update({\n",
        "          'scoring_function': self.scoring_function,\n",
        "          'att_units':self.att_units,\n",
        "          'wa':self.wa,\n",
        "          'w1':self.w1,\n",
        "          'w2':self.w2,\n",
        "          'v':self.v\n",
        "      })\n",
        "      return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "### 2.3 <font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Kc8m7lmOL097"
      },
      "outputs": [],
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "      super().__init__()\n",
        "      self.vocab_size = tar_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "      #Initialize Embedding layer\n",
        "      self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\", weights=[embedding_matrix_dec], trainable=False)\n",
        "      #Intialize Decoder LSTM layer\n",
        "      self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, name=\"Encoder_LSTM\") \n",
        "      #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "      self.dense   = Dense(self.vocab_size)\n",
        "      # self.dense   = Dense(self.vocab_size, activation='softmax')\n",
        "      self.attention                                                         = Attention(self.score_fun,self.att_units)\n",
        "      self.out_temp = []\n",
        "      self.decoder_final_state_h,self.decoder_final_state_c = [],[]\n",
        "      self.context_vector,self.attention_weights = [],[]\n",
        "      self.concat = []\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "    '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n",
        "    target_embedd                                                                   = self.embedding(input_to_decoder)\n",
        "    self.context_vector,self.attention_weights                                      = self.attention(state_h,encoder_output)\n",
        "\n",
        "    self.concat = tf.concat([tf.expand_dims(self.context_vector,1),target_embedd],axis=-1)\n",
        "    initial_states                                                                  = [state_h,state_c]\n",
        "    decoder_output,self.decoder_final_state_h,self.decoder_final_state_c            = self.lstm(self.concat, initial_state=initial_states)\n",
        "    # print(\"LSTM OUTPUT-->\",decoder_output[:5])\n",
        "    # decoder_output = tf.reshape(decoder_output,[tf.shape(decoder_output).numpy()[0],tf.shape(decoder_output).numpy()[2]])\n",
        "    decoder_output = tf.reshape(decoder_output,(-1,decoder_output.shape[2]))\n",
        "    output                                                                          = self.dense(decoder_output)\n",
        "    # print(\"DENSE OUTPUT-->\",output[:5])\n",
        "    # print(decoder_output.shape)\n",
        "    # print(output.shape)\n",
        "\n",
        "\n",
        "    return output,self.decoder_final_state_h,self.decoder_final_state_c,self.attention_weights,self.context_vector\n",
        "    # return np.array(output),self.decoder_final_state_h,self.decoder_final_state_c,self.attention_weights,self.context_vector\n",
        "\n",
        "  \n",
        "  def get_config(self):\n",
        "      config = super(One_Step_Decoder,self).get_config()\n",
        "      config.update({\n",
        "          'vocab_size': self.vocab_size,\n",
        "          'embedding_dim':self.embedding_dim,\n",
        "          'input_length':self.input_length,\n",
        "          'dec_units':self.dec_units,\n",
        "          'score_fun':self.score_fun,\n",
        "          'att_units':self.att_units,\n",
        "          'embedding':self.embedding,\n",
        "          'lstm':self.lstm,\n",
        "          'dense':self.dense,\n",
        "          'attention':self.attention,\n",
        "          'out_temp':self.out_temp,\n",
        "          'decoder_final_state_h':self.decoder_final_state_h,\n",
        "          'decoder_final_state_c':self.decoder_final_state_c,\n",
        "          'context_vector':self.context_vector,\n",
        "          'attention_weights':self.attention_weights,\n",
        "          'concat':self.concat,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "### 2.4 <font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "NV-x31rj6Hc4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super().__init__()\n",
        "      self.vocab_size = out_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "      #Initialize Embedding layer\n",
        "      self.onestep_decoder = One_Step_Decoder(self.vocab_size, self.embedding_dim, self.input_length, self.dec_units ,self.score_fun ,self.att_units)\n",
        "      self.all_outputs = tf.TensorArray(tf.float32,size=2,name=\"output_arrays\")\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "    \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        self.all_outputs = tf.TensorArray(tf.float32,size=tf.shape(input_to_decoder)[1],name=\"output_arrays\")\n",
        "      \n",
        "        #Iterate till the length of the decoder input\n",
        "        for timestep in range(tf.shape (input_to_decoder)[1]):\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            output,decoder_hidden_state,decoder_cell_state,_,_ = self.onestep_decoder(input_to_decoder[:,timestep:timestep+1],encoder_output,decoder_hidden_state,decoder_cell_state)\n",
        "            # Store the output in tensorarray\n",
        "            self.all_outputs = self.all_outputs.write(timestep,output)\n",
        "        # Return the tensor array.\n",
        "        # print(\"self.all_outputs shape-->\",self.all_outputs.size())\n",
        "        # print(\"self.all_outputs-->\",self.all_outputs)\n",
        "        self.all_outputs = tf.transpose(self.all_outputs.stack(),[1,0,2])\n",
        "        return self.all_outputs\n",
        "\n",
        "    \n",
        "    def get_config(self):\n",
        "      config = super(One_Step_Decoder,self).get_config()\n",
        "      config.update({\n",
        "          'vocab_size': self.vocab_size,\n",
        "          'embedding_dim':self.embedding_dim,\n",
        "          'input_length':self.input_length,\n",
        "          'dec_units':self.dec_units,\n",
        "          'score_fun':self.score_fun,\n",
        "          'att_units':self.att_units,\n",
        "          'onestep_decoder':self.onestep_decoder,\n",
        "          'all_outputs':self.all_outputs\n",
        "      })\n",
        "      return config\n",
        "        \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "### 2.5 <font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 70\n",
        "enc_units = 256\n",
        "embedding_dim = 100"
      ],
      "metadata": {
        "id": "1ZrNEZdsNqIt"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "FfqBIe20MT3D"
      },
      "outputs": [],
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,score_fun):\n",
        "    #Intialize objects from encoder decoder\n",
        "    super().__init__()\n",
        "    self.score_fun = score_fun\n",
        "    self.encoder = Encoder(inp_vocab_size=vocab_size_wrng + 1, embedding_size=embedding_dim, input_length=encoder_inputs_length, lstm_size=enc_units)#https://stackoverflow.com/questions/48479915/what-is-the-preferred-ratio-between-the-vocabulary-size-and-embedding-dimension\n",
        "    self.decoder = Decoder(out_vocab_size=vocab_size_corr + 1, embedding_dim=embedding_dim, input_length=decoder_inputs_length, dec_units=enc_units,score_fun=self.score_fun,att_units=enc_units)\n",
        "    self.decoder_output = []\n",
        "  \n",
        "  \n",
        "  def call(self,data):\n",
        "\n",
        "    input,output = data[0],data[1]\n",
        "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    print(\"=\"*20, \"ENCODER\", \"=\"*20)\n",
        "    batch_size = 16\n",
        "    enc_initial_state = self.encoder.initialize_states(batch_size)\n",
        "    encoder_output, encoder_h, encoder_c = self.encoder(input,enc_initial_state)\n",
        "    print(\"ENCODER ==> OUTPUT SHAPE\",encoder_output.shape)\n",
        "    print(\"ENCODER ==> HIDDEN STATE SHAPE\",encoder_h.shape)\n",
        "    # print(\"ENCODER ==> CELL STATE SHAPE\", encoder_c.shape)\n",
        "    # print(\"=\"*20, \"DECODER\", \"=\"*20)\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    dec_initial_state = [encoder_h,encoder_c]\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    self.decoder_output                             = self.decoder(output, encoder_output,encoder_h,encoder_c)\n",
        "    # return the decoder output\n",
        "    return self.decoder_output\n",
        "\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(One_Step_Decoder,self).get_config()\n",
        "    config.update({\n",
        "        'score_fun':self.score_fun,\n",
        "        'encoder':self.encoder,\n",
        "        'decoder':self.decoder,\n",
        "        'decoder_output':self.decoder_output\n",
        "    })\n",
        "    return config\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "### 2.6 <font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "QY_3izrXMs8y"
      },
      "outputs": [],
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqmICWSdREOu"
      },
      "source": [
        "### 2.7 <font color='blue'>Creating data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mBXRd_sus3C"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['wrong'].values\n",
        "        self.decoder_inps = data['corr_inp'].values\n",
        "        self.decoder_outs = data['corr_out'].values\n",
        "        self.wrng_tokenizer = tknizer_wrng\n",
        "        self.corr_tokenizer = tknizer_corr\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.wrng_tokenizer.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.corr_tokenizer.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.corr_tokenizer.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kl3ePGhCtKvJ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEUZFHrPREO0"
      },
      "source": [
        "### 2.8 <font color='blue'>Model loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "\n",
        "log_dir=\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/BACKUP DATA/TENSORBOARDS/dummy/logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7779db-5440-4560-b72f-66854af4ebad",
        "id": "WFIatq7HtK1Q"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDKh6iikRUyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e3ceef-5ef2-4075-e829-dd4e3bbda00c"
      },
      "source": [
        "train_dataset = Dataset(train[:2], tknizer_wrng, tknizer_corr, max_length)\n",
        "# test_dataset  = Dataset(validation[:2], tknizer_wrng, tknizer_corr, max_length)\n",
        "\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=2)\n",
        "# test_dataloader = Dataloder(test_dataset, batch_size=2)\n",
        "\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)\n",
        "# print(test_dataloader[0][0][0].shape, test_dataloader[0][0][1].shape, test_dataloader[0][1].shape)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 70) (2, 70) (2, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# full_model4 = encoder_decoder(encoder_inputs_length=max_length,decoder_inputs_length=max_length,output_vocab_size=vocab_size_corr,score_fun='dot')\n",
        "# optimizer = tf.keras.optimizers.Adam(0.001,clipnorm=0.001)\n",
        "# full_model4.compile(optimizer = optimizer,loss=loss_function)"
      ],
      "metadata": {
        "id": "1pXfzMzObzk1"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = full_model4.fit(train_dataloader, epochs=25, validation_data=test_dataloader,callbacks = callbacks)\n",
        "# full_model4.summary()"
      ],
      "metadata": {
        "id": "wZq24k0HbzgT"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full_model4.save_weights(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_BLEU_81.h5\")"
      ],
      "metadata": {
        "id": "ClkZebBBz0DA"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.9 <font color='blue'>Loading the weights"
      ],
      "metadata": {
        "id": "UPgHvb2l4wq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = encoder_decoder(encoder_inputs_length=max_length,decoder_inputs_length=max_length,output_vocab_size=vocab_size_corr,score_fun='dot')\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "dummy.compile(optimizer = optimizer,loss=loss_function)\n",
        "dummy.fit(train_dataloader, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh8xDLPUoc3G",
        "outputId": "d4604b75-67e0-47a8-de9e-e9a5040ff682"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== ENCODER ====================\n",
            "ENCODER ==> OUTPUT SHAPE (2, 70, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (2, 256)\n",
            "==================== ENCODER ====================\n",
            "ENCODER ==> OUTPUT SHAPE (None, None, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (None, 256)\n",
            "==================== ENCODER ====================\n",
            "ENCODER ==> OUTPUT SHAPE (None, None, 256)\n",
            "ENCODER ==> HIDDEN STATE SHAPE (None, 256)\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.8718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f98ab016d90>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy.load_weights('/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/MODELS/FINAL_ATTENTION_BLEU_49.h5')"
      ],
      "metadata": {
        "id": "LgkX_cLid_jj"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. PREDICT"
      ],
      "metadata": {
        "id": "o5AmezRCsB2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  input_sentence = input_sentence.replace(\"'\", '')\n",
        "  temp_token = tknizer_wrng.texts_to_sequences ( [ input_sentence ] )\n",
        "  temp_token  = pad_sequences ( temp_token , maxlen = vocab_size_wrng , dtype = 'int32' , padding = 'post' )\n",
        "\n",
        "\n",
        "\n",
        "  # print(\"=\" * 30, \"Inference\", \"=\" * 30)\n",
        "  initial_state =  [np.zeros((1,64)) ,np.zeros((1,64))]\n",
        "  enc_output, enc_state_h, enc_state_c = dummy.layers[0](np.expand_dims(temp_token[0], 0),initial_state)\n",
        "  states_values = [enc_state_h, enc_state_c]\n",
        "\n",
        "  dec_inp = np.array ( tknizer_corr.word_index ['<start>'] ).reshape( 1 , 1 )\n",
        "  attention_weights_list = []\n",
        "\n",
        "\n",
        "  predicted_eng = \"\"\n",
        "  for i in range(max_length):\n",
        "\n",
        "    predictions , enc_state_h , enc_state_c , attention_weights , context_vector = dummy.layers[ 1 ].onestep_decoder( dec_inp, enc_output , enc_state_h, enc_state_c )\n",
        "    \n",
        "    word_ind  = np.argmax ( predictions,-1 )\n",
        "    pred_str = list ( tknizer_corr.word_index.keys( ) ) [ int ( word_ind - 1 ) ]\n",
        "\n",
        "    attention_weights_list.append ( attention_weights [0,:,0 ] )\n",
        "\n",
        "    predicted_eng+= pred_str + \" \"\n",
        "\n",
        "    dec_inp = word_ind.reshape(1,1)\n",
        "\n",
        "    if(pred_str == \"<end>\"):\n",
        "      # print(predicted_eng)\n",
        "      return predicted_eng, np.array ( attention_weights_list )\n",
        "  return predicted_eng, np.array ( attention_weights_list )\n",
        "\n"
      ],
      "metadata": {
        "id": "VlcugX_pr_7X"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "def plot_attention ( attention , sentence , predicted_sentence ) :\n",
        "       \n",
        "    sentence  = sentence.split()\n",
        "    #final sentence declaration\n",
        "    sentence  = sentence \n",
        "    \n",
        "    predicted_sentence =  predicted_sentence.split() + [ '<end>' ]    \n",
        "    fig = plt.figure(figsize =( 10 , 10 ))\n",
        "    ax = fig.add_subplot (1 , 1 , 1)\n",
        "    attention = attention [:len ( predicted_sentence ), :len(sentence) ]\n",
        "    \n",
        "    #matrix plot with proper arguments\n",
        "    ax.matshow(attention, cmap = 'viridis', vmin = 0.0)\n",
        "\n",
        "    \n",
        "    #fontsize as 14\n",
        "    fontdict = {'fontsize': 14}\n",
        "    #seting up axis labels argument\n",
        "    ax.set_xticklabels( [''] + sentence , fontdict = fontdict , rotation = 90 )\n",
        "    ax.set_yticklabels( [''] + predicted_sentence , fontdict = fontdict)\n",
        "    ax.xaxis.set_major_locator ( matplotlib.ticker.MultipleLocator (1) )\n",
        "    ax.yaxis.set_major_locator ( matplotlib.ticker.MultipleLocator (1) )\n",
        "    \n",
        "    ax.set_xlabel ( 'Input text' )   \n",
        "    ax.set_ylabel ( 'Output text' )\n",
        "    \n",
        "    #titles\n",
        "    plt.suptitle ('Attention weights')\n",
        "\n"
      ],
      "metadata": {
        "id": "8Z0Ub-xy61Av"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. final_fun_1(X)"
      ],
      "metadata": {
        "id": "VAsKP6HPCI0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_fun_1(X):\n",
        "\n",
        "    punc = '''!()-[]{};:\"\\,<>./?@#$%^&*_~'''\n",
        "    max_length = 70\n",
        "    movie_quotes = X\n",
        "    processed_movie_quotes = []\n",
        "    results = []\n",
        "\n",
        "    # Removing punctuations in string\n",
        "    # Using loop + punctuation string\n",
        "    for test_str in movie_quotes:\n",
        "      for ele in test_str:\n",
        "          if ele in punc:\n",
        "              test_str = test_str.replace(ele, \"\")\n",
        "      processed_movie_quotes.append(test_str.lower())\n",
        "\n",
        "\n",
        "    for each in processed_movie_quotes:\n",
        "      pred_sent,attention_weights   = predict (each)\n",
        "      results.append(pred_sent.replace(\"<end>\",\"\"))\n",
        "    \n",
        "\n",
        "    df = pd.DataFrame(list(zip(movie_quotes, results)), columns =['INPUT', 'PREDICTED'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "c23BoYTd5nUY"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/data_500k.csv\")\n",
        "raw_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Iq3MzoTK5nM8",
        "outputId": "873b1ad4-d2ad-45e4-ff5e-e80aa8e496e2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      original       modified\n",
              "0  they do not  they due not \n",
              "1   they do to   they do too \n",
              "2    i hope so     i hope so \n",
              "3     she okay      she okay \n",
              "4     let's go      let's go "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ec7f80a-f840-44b9-a871-6e21d0e61b37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>modified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>they do not</td>\n",
              "      <td>they due not</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they do to</td>\n",
              "      <td>they do too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i hope so</td>\n",
              "      <td>i hope so</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she okay</td>\n",
              "      <td>she okay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>let's go</td>\n",
              "      <td>let's go</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ec7f80a-f840-44b9-a871-6e21d0e61b37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ec7f80a-f840-44b9-a871-6e21d0e61b37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ec7f80a-f840-44b9-a871-6e21d0e61b37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = raw_data[\"modified\"].tolist()\n",
        "results = final_fun_1(X[1234:1237])\n",
        "results.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "EeGgqV6q_wA1",
        "outputId": "edb32a1c-e35e-418f-b1fc-53a79075f96a"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               INPUT  \\\n",
              "0  yeah well ewe took the camera and put it right...   \n",
              "1  yes you are i'm not just some reporter aye don...   \n",
              "2                                             i not    \n",
              "\n",
              "                                           PREDICTED  \n",
              "0  yeah well you took the camera and put it right...  \n",
              "1  yes you are im not just some reporter i dont j...  \n",
              "2                                          i'm not    "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34adde0b-4ad3-4ad6-a282-7c911dc57351\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INPUT</th>\n",
              "      <th>PREDICTED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yeah well ewe took the camera and put it right...</td>\n",
              "      <td>yeah well you took the camera and put it right...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yes you are i'm not just some reporter aye don...</td>\n",
              "      <td>yes you are im not just some reporter i dont j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i not</td>\n",
              "      <td>i'm not</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34adde0b-4ad3-4ad6-a282-7c911dc57351')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34adde0b-4ad3-4ad6-a282-7c911dc57351 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34adde0b-4ad3-4ad6-a282-7c911dc57351');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uSJfVqQhAM3i"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. final_fun_2(X)"
      ],
      "metadata": {
        "id": "pHpgB0KiHAXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "\n",
        "def final_fun_2(X):\n",
        "\n",
        "    punc = '''!()-[]{};:\"\\,<>./?@#$%^&*_~'''\n",
        "    max_length = 70\n",
        "    input = X['modified'].tolist()\n",
        "    act_output = X['original'].tolist()\n",
        "    processed_movie_quotes = []\n",
        "    results = []\n",
        "\n",
        "    # Removing punctuations in string\n",
        "    # Using loop + punctuation string\n",
        "    for test_str in input:\n",
        "      for ele in test_str:\n",
        "          if ele in punc:\n",
        "              test_str = test_str.replace(ele, \"\")\n",
        "      processed_movie_quotes.append(test_str.lower())\n",
        "\n",
        "\n",
        "    for each in processed_movie_quotes:\n",
        "      pred_sent,attention_weights   = predict (each)\n",
        "      results.append(pred_sent.replace(\"<end>\",\"\"))\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    df = pd.DataFrame(list(zip(input, act_output, results)), columns =['INPUT', 'ACTUAL_OUTPUT', 'PREDICTED_OUTPUT'])\n",
        "\n",
        "    # print(act_output)\n",
        "    # print(results)\n",
        "    total_score = 0\n",
        "    for i in tqdm(range(len(input))):\n",
        "\n",
        "      reference = [act_output[i].split(),] # the original\n",
        "      translation = results[i].split()# trasilated using model\n",
        "      total_score += bleu.sentence_bleu(reference, translation)\n",
        "\n",
        "\n",
        "    avg_score = total_score/(len(input))\n",
        "\n",
        "\n",
        "\n",
        "    return avg_score"
      ],
      "metadata": {
        "id": "5-cf8mYsHFp3"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv(\"/content/drive/MyDrive/DATA SCIENCE/CASE STUDY 2/data_500k.csv\")\n",
        "X = raw_data.iloc[list(range(490500,490900,5))]\n",
        "final_score = final_fun_2(X)\n",
        "print(\"\\n\\n\\n\\n\\nFINAL SCORE--->\",final_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xar6tkzWHFmk",
        "outputId": "6f02b561-3908-4f20-ee16-ee87f0bd8362"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [00:00<00:00, 7377.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FINAL SCORE---> 0.7508849194569475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}